# Medal Prediction using Ensemble Learning

This project explores the application of ensemble learning techniquesâ€”such as Gradient Boosting, Random Forest, and XGBoostâ€”to predict Olympic medal counts (gold, silver, bronze, and total) based on structured national-level data. The focus lies on both **predictive performance** and **model interpretability**, with extended analyses such as SHAP value interpretation and uncertainty evaluation.

## ğŸ” Motivation

In scenarios involving moderately sized structured datasets with complex feature dependencies, ensemble models are often capable of achieving high prediction accuracy while maintaining robustness. This project aims to evaluate such models' performance in multi-target regression settings and investigate how feature importance and error distribution vary across sub-tasks.

## ğŸ“ Project Structure

```bash
machine-learning-practice/
â”œâ”€â”€ data/                        # Cleaned CSV files for medal prediction tasks
â”‚   â”œâ”€â”€ AllAverage.csv
â”‚   â”œâ”€â”€ GoldAverage.csv
â”‚   â”œâ”€â”€ SilverAverage.csv
â”‚   â”œâ”€â”€ BronzeAverage.csv
â”‚   â”œâ”€â”€ All_Predict.csv
â”‚   â”œâ”€â”€ Gold_Predict.csv
â”‚   â”œâ”€â”€ Silver_Predict.csv
â”‚   â””â”€â”€ Bronze_Predict.csv
â”œâ”€â”€ src/                         # Python scripts
â”‚   â”œâ”€â”€ main.py                  # Main training script (for total medal task)
â”‚   â”œâ”€â”€ drawmap.py               # Country-wise SHAP visualizer
â”‚   â”œâ”€â”€ draw_impo.py             # Feature importance plotter
â”‚   â”œâ”€â”€ draw_ratio_error.py      # Error/rÂ² trend visualizer
â”‚   â””â”€â”€ err.py                   # Custom error metric calculation
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ .gitignore
````

## ğŸ“Š Datasets

All datasets are stored in `./data/` and are pre-cleaned. They include historical medal performance, athlete numbers, and country-level sports indicators.

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/Artemiswe/machine-learning-practice.git
cd machine-learning-practice
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Run the main script

```bash
python src/main.py
```

Additional visualization scripts (e.g., SHAP maps, error trend analysis) can be run independently after training.

## ğŸ“ˆ Sample Outputs

* Feature Importance (SHAP)
* Key-Sport Distribution by Country (Map)
* Training/Test Error Curves
* Model Comparison Table (MAE, RMSE, RÂ², CPI)

All figures were generated using real model outputs and stored datasets.

## ğŸ›  Requirements

Main packages include:

* pandas
* numpy
* scikit-learn
* matplotlib
* shap
* seaborn
* optuna
* geopandas
* plotly

## ğŸ™Œ Acknowledgements

Special thanks to my teammate for their significant contribution in **data collection, cleaning, and preprocessing**, which laid the foundation for this project.


